{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e36337e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3568558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score, silhouette_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import statistics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb927f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f6242",
   "metadata": {},
   "source": [
    "Function for baseline model(stratified cross validation using random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bba557c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two possible code structures. \n",
    "#1st one by creating folds manually and then calculating accuracies of each permutation. \n",
    "#2nd one using built in function\n",
    "def base_model1(x, y):\n",
    "    x=x.values\n",
    "    y=y.values\n",
    "    rfc = RandomForestClassifier()\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) #creating 10 stratified folds\n",
    "    accuracies = []\n",
    "    f1_scores= []\n",
    "    \n",
    "    for train_index, test_index in skf.split(x, y): #performing cross validation\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        rfc.fit(x_train, y_train)     #fitting the model\n",
    "        predictions = rfc.predict(x_test)  #making predictions\n",
    "        \n",
    "        #saving different metrics in an array\n",
    "        accuracies.append(accuracy_score(y_test, predictions))\n",
    "        f1_scores.append(f1_score(y_test, predictions))\n",
    "    #taking mean of metrics\n",
    "    stratified_accuracy=statistics.mean(accuracies)\n",
    "    stratified_f1=statistics.mean(f1_scores)\n",
    "\n",
    "    #printing metrics\n",
    "    print('Mean Accuracy :',stratified_accuracy, ',Standard Deviation:', np.std(accuracies))\n",
    "    print('Mean F1 score :',stratified_f1,',Standard Deviation:', np.std(f1_scores))\n",
    "    \n",
    "    return stratified_accuracy, stratified_f1,accuracies,f1_scores\n",
    "def base_model(x, y):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    f1_scores = cross_val_score(RandomForestClassifier(), x,y, cv=cv,scoring='f1')\n",
    "    accuracies= cross_val_score(RandomForestClassifier(), x,y, cv=cv,scoring='accuracy')\n",
    "    stratified_f1=statistics.mean(f1_scores)\n",
    "    stratified_accuracy=statistics.mean(accuracies)\n",
    "    print('Mean Accuracy :',stratified_accuracy, ',Standard Deviation:', np.std(accuracies))\n",
    "    print('Mean F1 score :',stratified_f1,',Standard Deviation:', np.std(f1_scores))\n",
    "    \n",
    "    return stratified_accuracy, stratified_f1,accuracies,f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a83d68",
   "metadata": {},
   "source": [
    "Function for elbow method (code copied from lecture 5 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dea8e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(x):\n",
    "    inertias = []\n",
    "    for k in range(2, 9):\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        y_pred = kmeans.fit_predict(x)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "    # Let's plot inertia vs number of clusters\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(range(2, 9), inertias, 'o-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "    a= int(input(\"Enter the best possible value of k from elbow graph:\"))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddaa590",
   "metadata": {},
   "source": [
    "Function for Silhouette method (code copied from lecture 5 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f881697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(x):    \n",
    "    sil = []\n",
    "    for k in range(2, 9):\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        y_pred = kmeans.fit_predict(x)\n",
    "        sil.append(silhouette_score(x, y_pred))\n",
    "    # Let's plot SIL vs number of clusters\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(range(2, 9), sil, 'o-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "    a= int(input(\"Enter the best possible value of k from silhoutte graph:\"))\n",
    "    return a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74a5b7",
   "metadata": {},
   "source": [
    "Function for finding optimal k from values obtained from elbow and silhouette method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06249f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(lower,upper,x,y):\n",
    "    max=0\n",
    "    index=0\n",
    "    for i in range(lower, upper+1):\n",
    "        pred = KMeans(n_clusters=i).fit(x)\n",
    "        k=(f1_score(pred.labels_, y,average='weighted'))\n",
    "        if k>max:\n",
    "            max=k\n",
    "            index=i\n",
    "        \n",
    "    return index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a633f79",
   "metadata": {},
   "source": [
    "Function for proposed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "069bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(x, y):\n",
    "    accuracies = []\n",
    "    f1_scores= []\n",
    "    x=x.values\n",
    "    y=y.values\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)   #creating 10 stratified bins of the data\n",
    "    \n",
    "    for train_index, test_index in skf.split(x, y):              #iterating through all possible permutations\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #determining the value of k using elbow and silhouette methods\n",
    "        a=elbow(x_train)\n",
    "        b=silhouette(x_train)\n",
    "        if(a>=b):\n",
    "            upper_limit=a\n",
    "            lower_limit=b\n",
    "        else:\n",
    "            upper_limit=b\n",
    "            lower_limit=a\n",
    "        k=find_k(lower_limit,upper_limit,x_train,y_train)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=k, random_state=1).fit(x_train)   #running kmeans on dataset\n",
    "        k_labels=kmeans.labels_\n",
    "        centroids=kmeans.cluster_centers_                            #identifying clusters centroids\n",
    "        \n",
    "        minority_samples=[]\n",
    "        majority_samples=[]\n",
    "        for i in range(k):\n",
    "            a = np.where(k_labels == i)     \n",
    "            cluster_x = x_train[a]      \n",
    "            cluster_y = y_train[a] \n",
    "            samples=(cluster_y == 0).sum()                  #identifying number of samples of minority class in each cluster\n",
    "            minority_samples.append(samples)\n",
    "            samples1=(cluster_y==1).sum()\n",
    "            majority_samples.append(samples1)\n",
    "            \n",
    "        predictions = kmeans.predict(x_test)   #assigning values in unseen fold to nearest cluster \n",
    "        for i in range(k):\n",
    "            a = np.where(k_labels == i)     \n",
    "            cluster_x = x_train[a]      \n",
    "            cluster_y = y_train[a]\n",
    "            \n",
    "            if(minority_samples[i]>0 and majority_samples[i]>0):      #training random forest classifier for clusters having more than 1 classes instances\n",
    "                trained_models=RandomForestClassifier(max_depth=2, random_state=0)\n",
    "                trained_models.fit(cluster_x,cluster_y)\n",
    "                \n",
    "                for j in range(len(x_test)):\n",
    "                    if(predictions[j]==i):\n",
    "                        predictions[j]=trained_models.predict(np.reshape(x_test[j], (1,-1)))\n",
    "            else:\n",
    "                for j in range(len(x_test)):\n",
    "                    if(predictions[j]==i):\n",
    "                        predictions[j]=cluster_y[0]\n",
    "                        \n",
    "        #saving different metrics in an array\n",
    "        print(predictions)\n",
    "        accuracies.append(accuracy_score(y_test, predictions))\n",
    "        f1_scores.append(f1_score(y_test, predictions))\n",
    "        \n",
    "    #taking mean of metrics\n",
    "    stratified_accuracy=statistics.mean(accuracies)\n",
    "    stratified_f1=statistics.mean(f1_scores)\n",
    "    \n",
    "    #printing metrics\n",
    "    print('Mean Accuracy :',stratified_accuracy, ',Standard Deviation:', np.std(accuracies))\n",
    "    print('Mean F1 score :',stratified_f1,',Standard Deviation:', np.std(f1_scores))\n",
    "    \n",
    "    return stratified_accuracy, stratified_f1, accuracies,f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdb7c4",
   "metadata": {},
   "source": [
    "Permutation Test Function\n",
    "Note: Code used from my code in lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fad13d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permut_test(sample1, sample2,mean_sample1,mean_sample2, n_permutations):\n",
    "    pvalue=0\n",
    "    t_obs=mean_sample2-mean_sample1\n",
    "    for i in range(n_permutations):\n",
    "        sample=np.concatenate((sample1,sample2),axis=None)\n",
    "        permutate=np.random.permutation(sample)\n",
    "        pcurrent=permutate[:int(len(sample1))]\n",
    "        pnew=permutate[int(len(sample1)):]\n",
    "        pcurrent_mean=np.mean(pcurrent)\n",
    "        pnew_mean=np.mean(pnew)\n",
    "        t_perm=pnew_mean-pcurrent_mean\n",
    "        if(t_perm>t_obs):\n",
    "            pvalue=pvalue+1\n",
    "    pvalue=pvalue/n_permutations\n",
    "        \n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24748e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
